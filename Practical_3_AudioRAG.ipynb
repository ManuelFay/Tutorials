{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils ffmpeg\n",
        "!pip install fsspec==2023.9.2\n",
        "!pip install git+https://github.com/illuin-tech/colpali\n",
        "!pip install pdf2image av\n",
        "!pip install openai\n",
        "# !pip install --no-deps fast-plaid fastkmeans\n",
        "# !pip install torchvision --upgrade\n",
        "!pip install flash-attn==2.7.3 --no-build-isolation\n",
        "!pip install moviepy pydub\n",
        "!pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"
      ],
      "metadata": {
        "id": "2Rhb7a9IdyCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files, userdata\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import io\n",
        "from scipy.io import wavfile\n",
        "import io\n",
        "import base64\n",
        "from scipy.io.wavfile import write\n",
        "import requests\n",
        "from moviepy.editor import VideoFileClip\n",
        "from openai import OpenAI\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "api_key = userdata.get('OPENAI')\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "J3olXcVeLVKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploaded = files.upload()  # Choose your .mp4 file\n",
        "# # convert to WAV format\n",
        "# video = VideoFileClip(\"<local_file>.mp4\")\n",
        "# audio = video.audio\n",
        "# audio.write_audiofile(\"audio.wav\")"
      ],
      "metadata": {
        "id": "CmNKVf3aJh8F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a youtube video from URL\n",
        "# !yt-dlp https://www.youtube.com/watch?v=9vM4p9NN0Ts --extract-audio --audio-format wav -o \"audio.%(ext)s\"\n",
        "!yt-dlp https://www.youtube.com/watch?v=lsbcN9-jU1Y --extract-audio --audio-format wav -o \"audio.%(ext)s\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-_ZWWv-CGDQ",
        "outputId": "2020a3ec-04ad-4d46-b535-0c900fd53985"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=lsbcN9-jU1Y\n",
            "[youtube] lsbcN9-jU1Y: Downloading webpage\n",
            "[youtube] lsbcN9-jU1Y: Downloading tv client config\n",
            "[youtube] lsbcN9-jU1Y: Downloading player 69b31e11-main\n",
            "[youtube] lsbcN9-jU1Y: Downloading tv player API JSON\n",
            "[youtube] lsbcN9-jU1Y: Downloading ios player API JSON\n",
            "[youtube] lsbcN9-jU1Y: Downloading m3u8 information\n",
            "[info] lsbcN9-jU1Y: Downloading 1 format(s): 251\n",
            "[download] Destination: audio.webm\n",
            "\u001b[K[download] 100% of   27.26MiB in \u001b[1;37m00:00:01\u001b[0m at \u001b[0;32m17.07MiB/s\u001b[0m\n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk in 30s WAV files\n",
        "\n",
        "audios = []\n",
        "\n",
        "# Load original audio\n",
        "audio = AudioSegment.from_wav(\"audio.wav\")\n",
        "\n",
        "# Set target frame rate\n",
        "target_rate = 16000\n",
        "chunk_length_ms = 30 * 1000  # 30 seconds\n",
        "\n",
        "# Split and resample each chunk\n",
        "for i in range(0, len(audio), chunk_length_ms):\n",
        "    chunk = audio[i:i + chunk_length_ms]\n",
        "    # Optional: Convert stereo to mono to simplify\n",
        "    chunk = chunk.set_channels(1)\n",
        "\n",
        "    # Resample the chunk\n",
        "    chunk = chunk.set_frame_rate(target_rate)\n",
        "\n",
        "    # Export and convert to numpy array\n",
        "    buf = io.BytesIO()\n",
        "    chunk.export(buf, format=\"wav\")\n",
        "    buf.seek(0)\n",
        "\n",
        "    rate, data = wavfile.read(buf)\n",
        "    audios.append(data)\n",
        "\n",
        "print(f\"Number of chunks: {len(audios)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7UyXtEcK0lA",
        "outputId": "175fc5e8-7d0c-4341-9c10-3e960285bcb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's verify the audio sounds normal at 16k Hz\n",
        "display(Audio(audios[23], autoplay=False, rate=16000))"
      ],
      "metadata": {
        "id": "Wkk3tJmvL199"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers.utils.import_utils import is_flash_attn_2_available\n",
        "\n",
        "from colpali_engine.models import ColQwen2_5Omni, ColQwen2_5OmniProcessor\n",
        "\n",
        "\n",
        "model = ColQwen2_5Omni.from_pretrained(\n",
        "    \"vidore/colqwen-omni-v0.1\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"cuda\",  # or \"mps\" if on Apple Silicon\n",
        "    attn_implementation=\"flash_attention_2\" if is_flash_attn_2_available() else None,\n",
        ").eval()\n",
        "processor = ColQwen2_5OmniProcessor.from_pretrained(\"manu/colqwen-omni-v0.1\")"
      ],
      "metadata": {
        "id": "YCiYUGljcFue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_base64(data, rate=16000):\n",
        "    # Example: audios[1] and known sample rate (e.g., 16000)\n",
        "    # Save to BytesIO buffer\n",
        "    buf = io.BytesIO()\n",
        "    write(buf, rate, data)\n",
        "    buf.seek(0)\n",
        "\n",
        "    # Encode to base64\n",
        "    encoded_string = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
        "    return encoded_string\n",
        "\n",
        "def get_results(query: str, k=10):\n",
        "    batch_queries = processor.process_queries([query]).to(model.device)\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        query_embeddings = model(**batch_queries)\n",
        "\n",
        "    scores = processor.score_multi_vector(query_embeddings, ds)\n",
        "    # get top-5 scores\n",
        "    return scores[0].topk(k).indices.tolist()"
      ],
      "metadata": {
        "id": "OyQm-7CyT00d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Embedding the audio corpus (offline)"
      ],
      "metadata": {
        "id": "_MyYl_0pGLWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Process the input audios by batches of 4\n",
        "dataloader = DataLoader(\n",
        "    dataset=audios,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda x: processor.process_audios(x))\n",
        "\n",
        "ds  = []\n",
        "for batch_doc in tqdm(dataloader):\n",
        "    with torch.no_grad():\n",
        "        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n",
        "        embeddings_doc = model(**batch_doc)\n",
        "    ds.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVy7KSHEOJqs",
        "outputId": "2c016f25-6c1a-452b-a049-e590c5d4b9ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:08<00:00,  1.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ds[0].shape:\", ds[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lucqxpJyO_tg",
        "outputId": "ae018c2a-5bf7-4d81-8b36-458711d8f2b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ds[0].shape: torch.Size([804, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Embedding the query and matching the most relevant audios"
      ],
      "metadata": {
        "id": "utLs7zG7GTGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Was Hannibal well liked by his men?\"\n",
        "res = get_results(query)\n",
        "print(f\"The best audio chunks are: {res}\")\n",
        "# display(Audio(audios[res[0]], autoplay=False, rate=16000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX6Rl7mKOSnz",
        "outputId": "a85590f0-9c69-41f2-be76-eca3a5e11ad4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best audio chunks are: [26, 49, 42, 52, 51, 45, 44, 41, 43, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = [\n",
        "    {\n",
        "        \"type\": \"text\",\n",
        "        \"text\": f\"Answer the query using the audio files. Say which ones were used to answer. Query: {query}\"\n",
        "    }]\n",
        "\n",
        "for i in res[:5]:\n",
        "  content += [{\n",
        "      \"type\": \"text\",\n",
        "      \"text\": f\"The following is audio chunk # {i}.\"\n",
        "    },\n",
        "    {\n",
        "      \"type\": \"input_audio\",\n",
        "      \"input_audio\": {\n",
        "          \"data\": audio_to_base64(audios[i]),\n",
        "          \"format\": \"wav\"\n",
        "    }}]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-audio-preview\",\n",
        "    modalities=[\"text\", \"audio\"],\n",
        "    audio={\"voice\": \"ballad\", \"format\": \"wav\"},\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": content\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Answer: {completion.choices[0].message.audio.transcript}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpsLCLWzTAnZ",
        "outputId": "b1533950-32fb-4df7-fd20-c408ca436f6e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Was Hannibal well liked by his men?\n",
            "Answer: Based on the information from audio chunk 26, it mentions that Hannibal's men readily accepted him as their leader and that he had their total respect. This directly indicates that he was well liked by his men. Therefore, only the information from chunk 26 was used to answer the query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming completion.choices[0].message.audio.data is your base64 audio string\n",
        "wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
        "\n",
        "with open(\"response.wav\", \"wb\") as f:\n",
        "    f.write(wav_bytes)\n",
        "display(Audio(\"response.wav\", autoplay=False))"
      ],
      "metadata": {
        "id": "v7yZxEjyVLZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# And videos?"
      ],
      "metadata": {
        "id": "FnkLeymiUD_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Beware of OOM\n",
        "videos = [\"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerEscapes.mp4\", \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4\", \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4\"]"
      ],
      "metadata": {
        "id": "sUCALhwOR_r4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    dataset=videos,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda x: processor.process_videos(x),\n",
        ")\n",
        "\n",
        "ds  = []\n",
        "for batch_doc in tqdm(dataloader):\n",
        "    with torch.no_grad():\n",
        "        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n",
        "        embeddings_doc = model(**batch_doc)\n",
        "    ds.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkTg-sORZiqs",
        "outputId": "df458214-9001-4f7f-aae3-8e94126afb2e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]Unused or unrecognized kwargs: images.\n",
            " 33%|███▎      | 1/3 [00:05<00:10,  5.31s/it]Unused or unrecognized kwargs: images.\n",
            " 67%|██████▋   | 2/3 [00:09<00:04,  4.58s/it]Unused or unrecognized kwargs: images.\n",
            "100%|██████████| 3/3 [00:13<00:00,  4.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "queries = [\"A dragon spitting fire\"]\n",
        "\n",
        "# Process the inputs\n",
        "batch_queries = processor.process_queries(queries).to(model.device)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    query_embeddings = model(**batch_queries)\n",
        "\n",
        "scores = processor.score_multi_vector(query_embeddings, ds)\n",
        "# print(f\"The best video is video #{scores[0].argmax()}\")\n",
        "\n",
        "Video(videos[scores[0].argmax()], width=800)"
      ],
      "metadata": {
        "id": "udUcYREBGd2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Qs1CLrBcG47"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}